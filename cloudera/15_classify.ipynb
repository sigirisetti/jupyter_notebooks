{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f18dd-b029-4e9c-b601-b4783e6cf333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting and Evaluating Classification Models\n",
    "\n",
    "# Copyright © 2010–2020 Cloudera. All rights reserved.\n",
    "# Not to be reproduced or shared without prior written \n",
    "# consent from Cloudera.\n",
    "\n",
    "\n",
    "# ## Introduction\n",
    "\n",
    "# * A classification algorithm is a supervised learning algorithm\n",
    "#   * The inputs are called *features*\n",
    "#   * The output is called the *label*\n",
    "\n",
    "# * A classification model provides a prediction of a categorical label\n",
    "#   * Binary classification - two categories\n",
    "#   * Multiclass classification - three or more categories\n",
    "\n",
    "# * Spark MLlib provides several classification algorithms:\n",
    "#   * Logistic Regression (with Elastic Net, Lasso, and Ridge Regression)\n",
    "#   * Decision Tree\n",
    "#   * Random Forest\n",
    "#   * Gradient-Boosted Trees\n",
    "#   * Multilayer Perceptron (Neural Network)\n",
    "#   * Linear Support Vector Machine (SVM)\n",
    "#   * Naive Bayes\n",
    "\n",
    "# * Spark MLlib also provides a meta-algorithm for constructing multiclass\n",
    "# classification models from binary classification models:\n",
    "#   * One-vs-Rest\n",
    "\n",
    "# * Spark MLlib requires the features to be assembled into a vector of doubles column\n",
    "\n",
    "# * Spark MLlib requires the label to be a zero-based index\n",
    "\n",
    "\n",
    "# ## Scenario\n",
    "\n",
    "# In this module we will model the star rating of a ride as a function of\n",
    "# various attributes of the ride.  Rather than treat the star rating in its\n",
    "# original form, we will create a binary label that is true if the rating is\n",
    "# five stars and false otherwise.  We will use [logistic\n",
    "# regression](https://en.wikipedia.org/wiki/Logistic_regression) to construct a\n",
    "# binary classification model.  The general workflow will be similar for other\n",
    "# classification algorithms, although the particular details will vary.\n",
    "\n",
    "\n",
    "# ## Setup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "# ## Start a SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"classify\").getOrCreate()\n",
    "\n",
    "\n",
    "# ## Load the data\n",
    "\n",
    "# Read the enhanced (joined) ride data from HDFS:\n",
    "rides = spark.read.parquet(\"/duocar/joined/\")\n",
    "\n",
    "\n",
    "# ## Preprocess the modeling data\n",
    "\n",
    "# A cancelled ride does not have a star rating.  Use the\n",
    "# [SQLTransformer](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.SQLTransformer)\n",
    "# to filter out the cancelled rides:\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "filterer = SQLTransformer(statement=\"SELECT * FROM __THIS__ WHERE cancelled == 0\")\n",
    "filtered = filterer.transform(rides)\n",
    "\n",
    "# **Note:** `__THIS__` is a placeholder for the DataFrame passed into the `transform` method.\n",
    "\n",
    "\n",
    "# ## Generate label\n",
    "\n",
    "# We can treat `star_rating` as a continuous numerical label or an ordered\n",
    "# categorical label:\n",
    "filtered.groupBy(\"star_rating\").count().orderBy(\"star_rating\").show()\n",
    "\n",
    "# Rather than try to predict each value, let us see if we can distinguish\n",
    "# between five-star and non-five-star ratings.  We can use the\n",
    "# [Binarizer](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.Binarizer)\n",
    "# to create our binary label:\n",
    "from pyspark.ml.feature import Binarizer\n",
    "converted = filtered.withColumn(\"star_rating\", col(\"star_rating\").cast(\"double\"))\n",
    "binarizer = Binarizer(inputCol=\"star_rating\", outputCol=\"high_rating\", threshold = 4.5)\n",
    "labeled = binarizer.transform(converted)\n",
    "labeled.crosstab(\"star_rating\", \"high_rating\").show()\n",
    "\n",
    "# **Note:** `Binarizer` does not like integer values, thus we had to convert to doubles.\n",
    "\n",
    "\n",
    "# ## Extract, transform, and select features\n",
    "\n",
    "# Create function to explore features:\n",
    "def explore(df, feature, label, plot=True):\n",
    "  from pyspark.sql.functions import count, mean\n",
    "  aggregated = df.groupby(feature).agg(count(label), mean(label)).orderBy(feature)\n",
    "  aggregated.show()\n",
    "  if plot == True:\n",
    "    pdf = aggregated.toPandas()\n",
    "    pdf.plot.bar(x=pdf.columns[0], y=pdf.columns[2], capsize=5)\n",
    "\n",
    "# **Feature 1:** Did the rider review the ride?\n",
    "engineered1 = labeled.withColumn(\"reviewed\", col(\"review\").isNotNull().cast(\"int\"))\n",
    "explore(engineered1, \"reviewed\", \"high_rating\")\n",
    "\n",
    "# **Note:** The `avg(high_rating)` gives the observed fraction of a high ratings.\n",
    "\n",
    "# **Feature 2:** Does the year of the vehicle matter?\n",
    "explore(labeled, \"vehicle_year\", \"high_rating\")\n",
    "\n",
    "# **Note:** The rider is more likely to give a high rating when the car is\n",
    "# newer.  We will treat this variable as a continuous feature.\n",
    "\n",
    "# **Feature 3:** What about the color of the vehicle?\n",
    "explore(labeled, \"vehicle_color\", \"high_rating\")\n",
    "\n",
    "# **Note:** The rider is more likely to give a high rating if the car is\n",
    "# black and less likely to give a high rating if the car is yellow.\n",
    "\n",
    "# The classification algorithms in Spark MLlib do not accept categorical\n",
    "# features in this form, so let us convert `vehicle_color` to a set of dummy\n",
    "# variables. First, we use\n",
    "# [StringIndexer](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.StringIndexer)\n",
    "# to convert the string codes to numeric codes:\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"vehicle_color\", outputCol=\"vehicle_color_indexed\")\n",
    "indexer_model = indexer.fit(engineered1)\n",
    "list(enumerate(indexer_model.labels))\n",
    "indexed = indexer_model.transform(engineered1)\n",
    "indexed.select(\"vehicle_color\", \"vehicle_color_indexed\").show(5)\n",
    "\n",
    "# Then we use\n",
    "# [OneHotEncoderEstimator](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.OneHotEncoderEstimator)\n",
    "# to generate a set of dummy variables:\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "encoder = OneHotEncoderEstimator(inputCols=[\"vehicle_color_indexed\"], outputCols=[\"vehicle_color_encoded\"])\n",
    "encoder_model = encoder.fit(indexed)\n",
    "encoded = encoder_model.transform(indexed)\n",
    "encoded.select(\"vehicle_color\", \"vehicle_color_indexed\", \"vehicle_color_encoded\").show(5)\n",
    "\n",
    "# **Note:** `vehicle_color_encoded` is stored as a `SparseVector`.\n",
    "\n",
    "# Now we can (manually) select our features and label:\n",
    "selected = encoded.select(\"reviewed\", \"vehicle_year\", \"vehicle_color_encoded\", \"star_rating\", \"high_rating\")\n",
    "features = [\"reviewed\", \"vehicle_year\", \"vehicle_color_encoded\"]\n",
    "\n",
    "# The machine learning algorithms in Spark MLlib expect the features to be\n",
    "# collected into a single column, so we use\n",
    "# [VectorAssembler](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler)\n",
    "# to assemble our feature vector:\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "assembled = assembler.transform(selected)\n",
    "assembled.head(5)\n",
    "\n",
    "# **Note:** `features` is stored as a `SparseVector`.\n",
    "\n",
    "# Save data for subsequent modules:\n",
    "assembled.write.parquet(\"data/modeling_data\", mode=\"overwrite\")\n",
    "\n",
    "# **Note:** We are saving the data to our user directory in HDFS.\n",
    "\n",
    "\n",
    "# ## Create train and test sets\n",
    "\n",
    "# We will fit our model on the train DataFrame and evaluate our model on the\n",
    "# test DataFrame:\n",
    "(train, test) = assembled.randomSplit([0.7, 0.3], 12345)\n",
    "\n",
    "# **Important:**  Weights must be doubles.\n",
    "\n",
    "\n",
    "# ## Specify a logistic regression model\n",
    "\n",
    "# Use the\n",
    "# [LogisticRegression](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegression)\n",
    "# class to specify a logistic regression model:\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"high_rating\")\n",
    "\n",
    "# Use the `explainParams` method to get a full list of hyperparameters:\n",
    "print(log_reg.explainParams())\n",
    "\n",
    "\n",
    "# ## Fit the logistic regression model\n",
    "\n",
    "# Use the `fit` method to fit the logistic regression model on the train DataFrame:\n",
    "log_reg_model = log_reg.fit(train)\n",
    "\n",
    "# The result is an instance of the\n",
    "# [LogisticRegressionModel](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegressionModel)\n",
    "# class:\n",
    "type(log_reg_model)\n",
    "\n",
    "\n",
    "# ## Examine the logistic regression model\n",
    "\n",
    "# The model parameters are stored in the `intercept` and `coefficients` attributes:\n",
    "log_reg_model.intercept\n",
    "log_reg_model.coefficients\n",
    "\n",
    "# The `summary` attribute is an instance of the\n",
    "# [BinaryLogisticRegressionTrainingSummary](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary)\n",
    "# class:\n",
    "type(log_reg_model.summary)\n",
    "\n",
    "# We can query the iteration history:\n",
    "log_reg_model.summary.totalIterations\n",
    "log_reg_model.summary.objectiveHistory\n",
    "\n",
    "# and plot it too:\n",
    "def plot_iterations(summary):\n",
    "  plt.plot(summary.objectiveHistory)\n",
    "  plt.title(\"Training Summary\")\n",
    "  plt.xlabel(\"Iteration\")\n",
    "  plt.ylabel(\"Objective Function\")\n",
    "  plt.show()\n",
    "\n",
    "plot_iterations(log_reg_model.summary)\n",
    "\n",
    "# We can also query the model performance, in this case, the area under the ROC curve:\n",
    "log_reg_model.summary.areaUnderROC\n",
    "\n",
    "# and plot the ROC curve:\n",
    "log_reg_model.summary.roc.show(5)\n",
    "\n",
    "def plot_roc_curve(summary):\n",
    "  roc_curve = summary.roc.toPandas()\n",
    "  plt.plot(roc_curve[\"FPR\"], roc_curve[\"FPR\"], \"k\")\n",
    "  plt.plot(roc_curve[\"FPR\"], roc_curve[\"TPR\"])\n",
    "  plt.title(\"ROC Area: %s\" % summary.areaUnderROC)\n",
    "  plt.xlabel(\"False Positive Rate\")\n",
    "  plt.ylabel(\"True Positive Rate\")\n",
    "  plt.show()\n",
    "\n",
    "plot_roc_curve(log_reg_model.summary)\n",
    "\n",
    "\n",
    "# ## Evaluate model performance on the test set\n",
    "\n",
    "# We have been assessing the model performance on the train DataFrame.  We\n",
    "# really want to assess it on the test DataFrame.\n",
    "\n",
    "# **Method 1:** Use the `evaluate` method of the `LogisticRegressionModel` class\n",
    "\n",
    "test_summary = log_reg_model.evaluate(test)\n",
    "\n",
    "# The result is an instance of the\n",
    "# [BinaryLogisticRegressionSummary](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.BinaryLogisticRegressionSummary)\n",
    "# class:\n",
    "type(test_summary)\n",
    "\n",
    "# It has attributes similar to those of the\n",
    "# `BinaryLogisticRegressionTrainingSummary` class:\n",
    "test_summary.areaUnderROC\n",
    "plot_roc_curve(test_summary)\n",
    "\n",
    "# **Method 2:** Use the `evaluate` method of the\n",
    "# [BinaryClassificationEvaluator](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.BinaryClassificationEvaluator)\n",
    "# class\n",
    "\n",
    "# Generate predictions on the test DataFrame:\n",
    "test_with_prediction = log_reg_model.transform(test)\n",
    "test_with_prediction.show(5)\n",
    "\n",
    "# **Note:** The resulting DataFrame includes three types of predictions.  The\n",
    "# `rawPrediction` is a vector of log-odds, `prediction` is a vector or\n",
    "# probabilities `prediction` is the predicted class based on the probability\n",
    "# vector.\n",
    "\n",
    "# Create an instance of `BinaryClassificationEvaluator` class:\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"high_rating\", metricName=\"areaUnderROC\")\n",
    "print(evaluator.explainParams())\n",
    "evaluator.evaluate(test_with_prediction)\n",
    "\n",
    "# Evaluate using another metric:\n",
    "evaluator.setMetricName(\"areaUnderPR\").evaluate(test_with_prediction)\n",
    "\n",
    "\n",
    "# ## Exercises\n",
    "\n",
    "# In the exercises we add another feature to the classification model and\n",
    "# determine if it improves the model performance.\n",
    "\n",
    "# (1) Consider the `encoded` DataFrame.  Use the `explore` function to\n",
    "# determine if `vehicle_noir` is a promising feature.\n",
    "\n",
    "# (2) Reassemble the feature vector and include `vehicle_noir`.\n",
    "\n",
    "# (3) Create new train and test datasets.\n",
    "\n",
    "# (4) Refit the logistic regression model on the train dataset.\n",
    "\n",
    "# (5) Apply the refit logistic model to the test dataset.\n",
    "\n",
    "# (6) Compute the AUC on the test dataset.\n",
    "\n",
    "# (7) We committed a cardinal sin of machine learning above.  What was it?\n",
    "\n",
    "\n",
    "# ## References\n",
    "\n",
    "# [Spark Documentation - Classification and regression](https://spark.apache.org/docs/latest/ml-classification-regression.html)\n",
    "\n",
    "# [Spark Python API - pyspark.ml.feature module](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.feature)\n",
    "\n",
    "# [Spark Python API - pyspark.ml.classification module](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.classification)\n",
    "\n",
    "# [Spark Python API - pyspark.ml.evaluation module](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.evaluation)\n",
    "\n",
    "\n",
    "# ## Stop the SparkSession \n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
