{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08fd91-bafc-425e-8ed8-67ae491688c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Applying a scikit-learn Model to a Spark DataFrame\n",
    "\n",
    "# Copyright © 2010–2020 Cloudera. All rights reserved.\n",
    "# Not to be reproduced or shared without prior written \n",
    "# consent from Cloudera.\n",
    "\n",
    "\n",
    "# ## Introduction\n",
    "\n",
    "# We might want to use a machine learning algorithm that is not supported by\n",
    "# the Spark MLlib library.  In this case we can use our favorite Python package\n",
    "# to develop our machine learning model on a sample of data (on a single\n",
    "# machine) and then use a Spark UDF to apply the model to the full data (in our\n",
    "# Hadoop environment).  In this module we use the scikit-learn package to\n",
    "# rebuild the isotonic regression model we built earlier using Spark MLlib.  We\n",
    "# then use a pandas UDF to apply the model to a Spark DataFrame.\n",
    "\n",
    "\n",
    "# ## Setup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "# ## Prepare the data using Spark\n",
    "\n",
    "# We want to prepare our data and generate our features using Spark.\n",
    "# Otherwise, we will have to replicate any changes that we make to our sample\n",
    "# data on our full data before we can apply our machine learning model in\n",
    "# Spark.\n",
    "\n",
    "# ### Start a SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"deploy_udf\").getOrCreate()\n",
    "\n",
    "# ### Load the data\n",
    "\n",
    "rides = spark.read.parquet(\"/duocar/clean/rides/\")\n",
    "rides.printSchema()\n",
    "\n",
    "# ### Prepare the regression data\n",
    "\n",
    "# Select the feature and the label and filter out the cancelled rides:\n",
    "regression_data = rides.select(\"distance\", \"duration\").where(\"cancelled = FALSE\")\n",
    "\n",
    "\n",
    "# ## Build a scikit-learn model\n",
    "\n",
    "# We will use the [scikit-learn](https://scikit-learn.org/stable/) package to\n",
    "# develop an [isotonic\n",
    "# regression](https://en.wikipedia.org/wiki/Isotonic_regression) model.\n",
    "\n",
    "# ### Select a sample of data and load it into a pandas DataFrame\n",
    "\n",
    "modeling_data = regression_data \\\n",
    "  .sample(withReplacement=False, fraction=0.1, seed=12345) \\\n",
    "  .toPandas()\n",
    "\n",
    "# ### Plot the data\n",
    "\n",
    "modeling_data.plot(x=\"distance\", y=\"duration\", kind=\"scatter\", color=\"orange\")\n",
    "\n",
    "# ### Specify the features and label\n",
    "\n",
    "features = modeling_data['distance']\n",
    "label = modeling_data['duration']\n",
    "\n",
    "# ### Create train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, label_train, label_test = train_test_split(features, label, test_size=0.3, random_state=42)\n",
    "\n",
    "# ### Specify and fit an isotonic regression model\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "ir.fit(features_train, label_train)\n",
    "\n",
    "# **Note:** The `out_of_bounds` argument determines how feature values outside\n",
    "# the range of training values are handled during prediction.\n",
    "\n",
    "# ### Evaluate the isotonic regression model\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Apply the model to the train and test datasets:\n",
    "label_train_predicted = ir.predict(features_train)\n",
    "label_test_predicted = ir.predict(features_test)\n",
    "\n",
    "# Compute the RMSE on the train and test datasets:\n",
    "sqrt(mean_squared_error(label_train, label_train_predicted))\n",
    "sqrt(mean_squared_error(label_test, label_test_predicted))\n",
    "\n",
    "# **Note:** These RMSE values are consistent with our results using Spark\n",
    "# MLlib.\n",
    "\n",
    "# ### Plot the isotonic regression model\n",
    "\n",
    "def plot_model():\n",
    "  fig = plt.figure()\n",
    "  plt.scatter(features_test, label_test, s=12, c=\"orange\", alpha=0.25)\n",
    "  # Use plt.plot rather than plt.step since sklearn does linear interpolation.\n",
    "  plt.plot(ir.f_.x, ir.f_.y, color=\"black\")\n",
    "  plt.title(\"Isotonic Regression on Test Set\")\n",
    "  plt.xlabel(\"Distance (m)\")\n",
    "  plt.ylabel(\"Duration (s)\")\n",
    "plot_model()\n",
    "\n",
    "# ### Save the model for later use in CDSW\n",
    "\n",
    "# Use the pickle package to serialize the model on disk:\n",
    "import pickle\n",
    "with open(\"ir_model.pickle\", \"wb\") as f:\n",
    "  pickle.dump(ir, f)\n",
    "\n",
    "\n",
    "# ## Apply the model using a Spark UDF\n",
    "\n",
    "# We will use the more efficient pandas UDF, which processes multiple rows of\n",
    "# data rather than a single row of data, to apply our model to a Spark\n",
    "# DataFrame.  The Spark executors must have access to our model.  We can let\n",
    "# Spark automatically *broadcast* the model to the executors or we can manually\n",
    "# broadcast it.\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# ### Automatically broadcast the model to the executors\n",
    "\n",
    "# Define and register our pandas UDF:\n",
    "@pandas_udf(DoubleType(), PandasUDFType.SCALAR)\n",
    "def predict_udf(x):\n",
    "  return pd.Series(ir.predict(x))\n",
    "\n",
    "# Normally our UDF will take multiple columns representing multiple features\n",
    "# (or a single column representing a feature vector) and it will reshape the\n",
    "# input into a form appropriate for the specific model predict method.\n",
    "\n",
    "# The Spark driver will distribute the *closure* of the Python function to the\n",
    "# Spark executors.  The closure consists of the function and its environment.\n",
    "# In this case the closure includes the `ir` instance and its `predict` method.\n",
    "\n",
    "# Use the UDF to apply the model to our Spark DataFrame:\n",
    "regression_data.withColumn(\"duration_predicted\", predict_udf(\"distance\")).show(5)\n",
    "\n",
    "# **Note:** You will have to deal with null (missing) values before calling the\n",
    "# UDF or handle them within the UDF.\n",
    "\n",
    "# **Important:** This code will fail when running Spark via YARN if `pyarrow`\n",
    "# is not installed on all the worker nodes.\n",
    "\n",
    "# ### Manually broadcast the model to the executors\n",
    "\n",
    "# Rather than let the Spark driver distribute our model, we can explicitly\n",
    "# broadcast it to the Spark executors:\n",
    "bc_ir_model = spark.sparkContext.broadcast(ir)\n",
    "\n",
    "# Define and register our pandas UDF:\n",
    "@pandas_udf(DoubleType(), PandasUDFType.SCALAR)\n",
    "def bc_predict_udf(x):\n",
    "  return pd.Series(bc_ir_model.value.predict(x))\n",
    "\n",
    "# Use the UDF to apply the model to our Spark DataFrame:\n",
    "data_with_prediction = regression_data.withColumn(\"duration_predicted\", bc_predict_udf(\"distance\"))\n",
    "data_with_prediction.show(5)\n",
    "\n",
    "# ### Evaluate the model\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(predictionCol=\"duration_predicted\", labelCol=\"duration\", metricName=\"rmse\")\n",
    "evaluator.evaluate(data_with_prediction)\n",
    "\n",
    "\n",
    "# ## Exercises\n",
    "\n",
    "# None\n",
    "\n",
    "\n",
    "# ## References\n",
    "\n",
    "# [scikit-learn Documentation - IsotonicRegression\n",
    "# class](https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html?highlight=isotonic#sklearn-isotonic-isotonicregression)\n",
    "\n",
    "# [Spark Python API - pandas_udf\n",
    "# function](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.pandas_udf)\n",
    "\n",
    "# [Spark Programming Guide - Broadcast\n",
    "# Variables](https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#broadcast-variables)\n",
    "\n",
    "\n",
    "# ## Cleanup\n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
