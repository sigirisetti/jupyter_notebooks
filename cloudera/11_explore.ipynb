{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e34e3-f300-4bb5-918c-bacec3918e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exploring and Visualizing DataFrames\n",
    "\n",
    "# Copyright © 2010–2020 Cloudera. All rights reserved.\n",
    "# Not to be reproduced or shared without prior written \n",
    "# consent from Cloudera.\n",
    "\n",
    "\n",
    "# ## Overview\n",
    "\n",
    "# Now that we have enhanced our ride data, we can begin a more systematic\n",
    "# exploration of the relationships among the variables.  The insight gathered\n",
    "# during this analysis may be used to improve DuoCar's day-to-day business\n",
    "# operations or it may serve as preparation for more sophisticated analysis and\n",
    "# modeling using machine learning algorithms.  In this module we use Spark in\n",
    "# conjunction with some popular Python libraries to explore the DuoCar data.\n",
    "\n",
    "\n",
    "# ## Possible work flows for big data\n",
    "\n",
    "# * Work with all of the data on the cluster\n",
    "#   * Produces accurate reports\n",
    "#   * Limits analysis to tabular reports\n",
    "#   * Requires more computation\n",
    "# * Work with a sample of the data in local memory\n",
    "#   * Opens up a wide range of tools\n",
    "#   * Enables more rapid iterations\n",
    "#   * Produces sampled results\n",
    "# * Summarize on the cluster and visualize summarized data in local memory\n",
    "#   * Produces accurate counts\n",
    "#   * Allows for wide range of analysis and visualization tools\n",
    "\n",
    "\n",
    "# ## Setup\n",
    "\n",
    "# Import useful packages, modules, classes, and functions:\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a SparkSession:\n",
    "spark = SparkSession.builder.appName(\"explore\").getOrCreate()\n",
    "\n",
    "# Load the enhanced ride data from HDFS:\n",
    "rides_sdf = spark.read.parquet(\"/duocar/joined_all\")\n",
    "\n",
    "# Create a random sample and load it into a pandas DataFrame:\n",
    "rides_pdf = rides_sdf.sample(withReplacement=False, fraction=0.01, seed=12345).toPandas()\n",
    "\n",
    "# **Note:** In this module we will use `sdf` to denote Spark DataFrames and\n",
    "# `pdf` to denote pandas DataFrames.\n",
    "\n",
    "\n",
    "# ## Exploring a single variable\n",
    "\n",
    "# In this section we use Spark and Spark in conjunction with pandas,\n",
    "# matplotlib, and seaborn to explore a single variable (i.e., column).  Many of\n",
    "# the techniques presented here can be useful when inspecting variables too.\n",
    "\n",
    "# ### Exploring a categorical variable\n",
    "\n",
    "# Let us explore type of car service, which is an example of a categorical\n",
    "# variable.\n",
    "\n",
    "# We can use the `groupBy` method in Spark to create a one-way frequency table:\n",
    "summarized_sdf = rides_sdf.groupBy(\"service\").count().orderBy(\"service\")\n",
    "summarized_sdf.show()\n",
    "\n",
    "# We can convert the grouped Spark DataFrame to a pandas DataFrame:\n",
    "summarized_pdf = summarized_sdf.toPandas()\n",
    "summarized_pdf\n",
    "\n",
    "# **Note**: Remember that we are loading data into local memory.  In this case\n",
    "# we are safe since the summarized DataFrame is small.\n",
    "\n",
    "# Specify the desired order of the categories:\n",
    "order = [\"Car\", \"Noir\", \"Grand\", \"Elite\"]\n",
    "\n",
    "# Use the seaborn package to plot the *summarized* data:\n",
    "sns.barplot(x=\"service\", y=\"count\", data=summarized_pdf, order=order)\n",
    "\n",
    "# Use the seaborn package to plot the *sampled* data:\n",
    "sns.countplot(x=\"service\", data=rides_pdf, order=order)\n",
    "\n",
    "# **Note:** The plots present the same qualitative information.\n",
    "\n",
    "\n",
    "# ### Exploring a continuous variable\n",
    "\n",
    "# We can use the `describe` method to compute basic summary statistics:\n",
    "rides_sdf.describe(\"distance\").show()\n",
    "\n",
    "# and aggregate functions to get additional summary statistics:\n",
    "rides_sdf.agg(skewness(\"distance\"), kurtosis(\"distance\")).show()\n",
    "\n",
    "# We can use the `approxQuantile` method to compute approximate quantiles:\n",
    "rides_sdf.approxQuantile(\"distance\", probabilities=[0.0, 0.05, 0.25, 0.5, 0.75, 0.95, 1.0], relativeError=0.1)\n",
    "\n",
    "# **Note:** Set `relativeError = 0.0` for exact (and possibly expensive)\n",
    "# quantiles.\n",
    "\n",
    "# However, a histogram is generally more informative than summary statistics.\n",
    "# Create an approximate 1% random sample:\n",
    "sampled_pdf = rides_sdf \\\n",
    "  .select(\"distance\") \\\n",
    "  .dropna() \\\n",
    "  .sample(withReplacement=False, fraction=0.01, seed=23456) \\\n",
    "  .toPandas()\n",
    "\n",
    "# Use seaborn to create a histogram on the *sampled* data:\n",
    "sns.distplot(sampled_pdf[\"distance\"], kde=False)\n",
    "\n",
    "# Use seaborn to create a *normalized* histogram with rug plot and kernel\n",
    "# density estimate:\n",
    "sns.distplot(sampled_pdf[\"distance\"], kde=True, rug=True)\n",
    "\n",
    "# Use seaborn to create a boxplot, which displays much of the information\n",
    "# computed via the `approxQuantile` method:\n",
    "sns.boxplot(x=\"distance\", data=sampled_pdf)\n",
    "\n",
    "\n",
    "# ## Exploring a pair of variables\n",
    "\n",
    "# ### Categorical-Categorical\n",
    "\n",
    "# Let us explore the distribution of a rider's gender by student status.\n",
    "\n",
    "# Create a two-way frequency table:\n",
    "summarized_sdf = rides_sdf.groupBy(\"rider_student\", \"rider_gender\").count().orderBy(\"rider_student\", \"rider_gender\")\n",
    "summarized_sdf.show()\n",
    "\n",
    "# Convert the *summarized* Spark DataFrame to a pandas DataFrame:\n",
    "summarized_pdf = summarized_sdf.toPandas()\n",
    "summarized_pdf\n",
    "\n",
    "# Produce a bar chart using seaborn:\n",
    "hue_order = [\"female\", \"male\"]\n",
    "sns.barplot(x=\"rider_student\", y=\"count\", hue=\"rider_gender\", hue_order=hue_order, data=summarized_pdf)\n",
    "\n",
    "# Replace missing values:\n",
    "summarized_pdf = summarized_sdf.fillna(\"missing\").toPandas()\n",
    "hue_order = [\"female\", \"male\", \"missing\"]\n",
    "sns.barplot(x=\"rider_student\", y=\"count\", hue=\"rider_gender\", hue_order=hue_order, data=summarized_pdf)\n",
    "\n",
    "# ### Categorical-Continuous\n",
    "\n",
    "# Let us explore the distribution of ride distance by rider student status.\n",
    "\n",
    "# We can produce tabular reports in Spark:\n",
    "rides_sdf \\\n",
    "  .groupBy(\"rider_student\") \\\n",
    "  .agg(count(\"distance\"), mean(\"distance\"), stddev(\"distance\")) \\\n",
    "  .orderBy(\"rider_student\") \\\n",
    "  .show()\n",
    "\n",
    "# Alternatively, we can produce visualizations on a sample:\n",
    "sampled_pdf = rides_sdf \\\n",
    "  .select(\"rider_student\", \"distance\") \\\n",
    "  .sample(withReplacement=False, fraction=0.01, seed=34567) \\\n",
    "  .toPandas()\n",
    "\n",
    "# Use seaborn to produce a strip plot on the sampled data:\n",
    "sns.stripplot(x=\"rider_student\", y=\"distance\", data=sampled_pdf, jitter=True)\n",
    "\n",
    "# **Note:** Non-students are taking the long rides.\n",
    "\n",
    "# See the supplement for other ways to visualize this data.\n",
    "\n",
    "\n",
    "# ### Continuous-Continuous\n",
    "\n",
    "# Use the `corr`, `covar_samp`, and `covar_pop` aggregate functions to measure\n",
    "# the linear relationship between two variables:\n",
    "rides_sdf.agg(corr(\"distance\", \"duration\"),\n",
    "              covar_samp(\"distance\", \"duration\"),\n",
    "              covar_pop(\"distance\", \"duration\")).show()\n",
    "\n",
    "# Use the `jointplot` function to produce an enhanced scatter plot on the\n",
    "# *sampled* data:\n",
    "sns.jointplot(x=\"distance\", y=\"duration\", data=rides_pdf)\n",
    "\n",
    "# Overlay a linear regression model:\n",
    "sns.jointplot(x=\"distance\", y=\"duration\", data=rides_pdf, kind=\"reg\")\n",
    "\n",
    "# Overlay a quadratic regression model (order = 2):\n",
    "sns.jointplot(x=\"distance\", y=\"duration\", data=rides_pdf, kind=\"reg\", order=2)\n",
    "\n",
    "# Use the `pairplot` function to examine several pairs at once:\n",
    "sampled_pdf = rides_sdf \\\n",
    "  .select(\"distance\", \"duration\", hour(\"date_time\")) \\\n",
    "  .dropna() \\\n",
    "  .sample(withReplacement=False, fraction=0.01, seed=45678) \\\n",
    "  .toPandas()\n",
    "sns.pairplot(sampled_pdf)\n",
    "\n",
    "\n",
    "# ## Exercises\n",
    "\n",
    "# (1) Look for variables that might help us predict ride duration.\n",
    "\n",
    "# (2) Look for variables that might help us predict ride rating.\n",
    "\n",
    "\n",
    "# ## References\n",
    "\n",
    "# [The SciPy Stack](https://scipy.org/)\n",
    "\n",
    "# [pandas](http://pandas.pydata.org/)\n",
    "\n",
    "# [matplotlib](https://matplotlib.org/index.html)\n",
    "\n",
    "# [seaborn](https://seaborn.pydata.org/index.html)\n",
    "\n",
    "# [Bokeh](http://bokeh.pydata.org/en/latest/)\n",
    "\n",
    "# [Plotly](https://plot.ly/)\n",
    "\n",
    "\n",
    "# ## Cleanup\n",
    "\n",
    "# Stop the SparkSession:\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
